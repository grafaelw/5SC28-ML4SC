{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning for Systems & Control 5SC28 2021-2022\n",
    "\n",
    "# Exercise set Lecture 2: Gaussian Processes\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "1. <a href=\"#Exercise-1:-Writing-your-own-GP\">Exercise 1: Writing your own GP</a>\n",
    "2. <a href=\"#Exercise-2:-Using-sklearn-GP\">Exercise 2: Using sklearn GP</a>\n",
    "3. <a href=\"#(Optional)-Exercise-3:-NARX-GP\">(Optional) Exercise 3: NARX GP</a>\n",
    "4. <a href=\"#Exercise-4:-Bayesian-optimization\">Exercise 4: Bayesian optimization</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise set, you will implement your own version of a Radial Basis Function Gaussian Process, explore its properties and how it can be used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Writing your own GP\n",
    "\n",
    "**a)** Based on Slide 32 and 20 for Lecture 2, implement GP regression with $\\sigma_e^2 = 0.1$ (expected noise variance) and a squared exponential kernel with $\\sigma^2 = 0.1$ (kernel width) using the `lownoise.mat` data set (place contents of the `dataW2.zip` in the same folder as the notebook) and plot the resulting function estimate on a fine grid of `xtest = np.linspace(-1,1,num=300)`. Analyse the qualitative fit w.r.t. the data. \n",
    "\n",
    "*tip: start by (i) finishing the `kernel` function. Next, use the `kernel` function in (ii) `compute_alpha` and in (iii) `pred_mean_and_var` to compute the mean.*\n",
    "\n",
    "*tip: use np.linalg.solve instead of np.linalgh.inv*\n",
    "\n",
    "$\\hat \\alpha = \\left ( K_{xx} + \\sigma_e^2 I_N \\right ) ^{-1} Y$\n",
    "\n",
    "**b)** Compute the resulting variance of the function estimate (slide 20) of 1.a and plot the 95% confidence bound (2 times the standard deviation) of the function. You can use the second part of `pred_mean_and_var` to complete this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "######### Calling the dataset '1' or '2'  #########\n",
    "ident_train = '1'\n",
    "ident_test = '2'\n",
    "path = os.getcwd()\n",
    "datapath = path + '/data_sets'\n",
    "\n",
    "#load data\n",
    "train_data = np.load(datapath + f'/disk-measurement-dataset-{ident_train}.npz') #train data\n",
    "X_train, y_train = train_data['u'], train_data['th'] # inputs\n",
    "t = train_data['t'] # time samples\n",
    "test_data = np.load(datapath + f'/disk-measurement-dataset-{ident_test}.npz') #validation data\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(test_data['u'], test_data['th'])\n",
    "\n",
    "xtest = np.linspace(-1,1,num=1000) #xpoints for visualization\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(t,X_train)\n",
    "plt.xlabel('time (sec)')\n",
    "plt.ylabel('input (V)')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(t,y_train)\n",
    "plt.xlabel('time (sec)')\n",
    "plt.ylabel('$\\\\theta$ (rad)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "def kernel(x1, x2, sigma2_ker):\n",
    "    '''\n",
    "    #make a matrix for two given inputs arrays\n",
    "    #input: \n",
    "    #x1 of shape (N1)\n",
    "    #x2 of shape (N2)\n",
    "    #sigma2_ker float the squared kernel width\n",
    "    \n",
    "    #output\n",
    "    #Kxx of shape (N1,N2)\n",
    "    #Kxx[i,j] = np.exp(-(x1[i]-x2[j])**2/(2*sigma2_ker))) #a)\n",
    "    '''\n",
    "    #fast and compact: #a)\n",
    "    diff = x1[:,None] - x2[None,:] #make a diff matrix of size (N1,N2) #a)\n",
    "    Kxx = np.exp(-diff**2/(2*sigma2_ker)) #a)\n",
    "    \n",
    "#     #slow and explicit: #a)\n",
    "#     Kxx = np.zeros(shape=(len(x1),len(x2))) #a)\n",
    "#     for i in range(len(x1)): #a)\n",
    "#         for j in range(len(x2)): #a)\n",
    "#             Kxx[i,j] = np.exp(-(x1[i]-x2[j])**2/(2*sigma2_ker)) #a)\n",
    "    \n",
    "    return Kxx\n",
    "\n",
    "def compute_alpha(x, y, sigma2_es, sigma2_ker):\n",
    "    #for a given x and y data computes the alpha and Kxx \n",
    "    #uses the kernel function from above\n",
    "\n",
    "    Kxx = kernel(x, x, sigma2_ker) #a=)\n",
    "    alpha = np.linalg.solve(Kxx+sigma2_es*np.eye(len(x)), y) #a=)\n",
    "    return alpha, Kxx #return both alpha and Kxx (required for variance estimation)\n",
    "\n",
    "    \n",
    "    \n",
    "def pred_mean_and_var(xtest, x, Kxx, alpha, sigma2_es, sigma2_ker, return_std=True): \n",
    "    #conditionally return the standard deviation  \n",
    "    K = lambda x1,x2: kernel(x1, x2, sigma2_ker=sigma2_ker) #shorthand for the kernel function use as K(x1,x2)\n",
    "    \n",
    "    Ktx = K(xtest, x) #a=)\n",
    "    Ypred_mean = Ktx@alpha #a=)\n",
    "    \n",
    "    if not return_std:\n",
    "        return Ypred_mean\n",
    "\n",
    "    #finished at b)\n",
    "#     Ypred_var = \n",
    "    #slow way: #b) \n",
    "    #Ypred_var = np.diag(K(xtest,xtest) - Ktx@np.linalg.inv(Kxx+sigma2_es*np.eye(len(x)))@Ktx.T) #b)\n",
    "    #fast way: #b)\n",
    "    Ypred_var = np.diag(K(xtest,xtest) - Ktx@np.linalg.solve(Kxx+sigma2_es*np.eye(len(x)), Ktx.T)) #b)\n",
    "    \n",
    "    return Ypred_mean, Ypred_var**0.5\n",
    "    \n",
    "sigma2_es = 0.1\n",
    "sigma2_ker = 0.1\n",
    "alpha, Kxx = compute_alpha(X_train, y_train, sigma2_es, sigma2_ker) # a) finish compute_alpha  \n",
    "Ypred_mean = pred_mean_and_var(X_test, X_train, Kxx, alpha, sigma2_es, sigma2_ker, return_std=False) # a) finish pred_mean_and_var  \n",
    "\n",
    "plt.plot(X_train,y_train,'.')\n",
    "plt.plot(xtest,Ypred_mean)\n",
    "plt.ylabel('y'); plt.xlabel('x'); plt.legend(['training data','mean predicted value']); plt.grid()\n",
    "plt.title('pred mean')\n",
    "plt.show()\n",
    "\n",
    "if False: #switch to true when on b)\n",
    "    Ypred_mean, Ypred_std = pred_mean_and_var(xtest, x, Kxx, alpha, sigma2_es, sigma2_ker)\n",
    "    plt.plot(x,y,'.')\n",
    "    plt.plot(xtest,Ypred_mean,'-')\n",
    "    plt.fill_between(xtest,Ypred_mean-2*Ypred_std,Ypred_mean+2*Ypred_std,alpha=0.3)\n",
    "    plt.ylabel('y'); plt.xlabel('x'); plt.legend(['training data','mean predicted value','predicted std']); plt.grid();\n",
    "    plt.title('pred mean and std')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Write down the influence of the kernel width $\\sigma$ and the $\\sigma_e$ on the predictions using the figures generated in the cell below.\n",
    "\n",
    "**Answer c):** $\\sigma_e$ regulates the uncertainty of each measurement point and $\\sigma$ regulates the area each point can influence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x,y,xtest,sigma2_es,sigma2_ker):\n",
    "    \n",
    "    alpha, Kxx = compute_alpha(x, y, sigma2_es, sigma2_ker)\n",
    "    Ypred_mean, Ypred_std = pred_mean_and_var(xtest, x, Kxx, alpha, sigma2_es, sigma2_ker)\n",
    "    \n",
    "    plt.title(f'$\\\\sigma^2 = {sigma2_ker}$, $\\\\sigma^2_e = {sigma2_es}$ ')\n",
    "    plt.plot(x,y,'.')\n",
    "    plt.plot(xtest,Ypred_mean)\n",
    "    plt.fill_between(xtest,Ypred_mean-2*Ypred_std,Ypred_mean+2*Ypred_std,alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.grid()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "i = 0\n",
    "for sigma2_es in [0.01,0.1,1.0]:\n",
    "    for sigma2_ker in [0.01,0.1,1.0]:\n",
    "        i+=1\n",
    "        plt.subplot(3,3,i)\n",
    "        plot(x,y,xtest,sigma2_es,sigma2_ker)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Implement a grid search for $\\sigma_e$ and $\\sigma$ using the validation set (`xval` and `yval`). Complete the RMS function below and iterate over both arrays to create the grid. Use the cell after the next one to visualize the result. Does this result seem sensible?\n",
    "\n",
    "**Answer d):** The obtained $\\sigma_e$ is significantly lower than it should be which results in a standard deviation way too small (i.e. the results are overly confident). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMS(x, y, xval, yval, sigma2_es, sigma2_ker):\n",
    "    alpha, Kxx = compute_alpha(x, y, sigma2_es, sigma2_ker) #d)\n",
    "    yval_mean_pred = pred_mean_and_var(xval, x, Kxx, alpha, sigma2_es, sigma2_ker, return_std=False) #d)\n",
    "    return np.mean((yval_mean_pred - yval)**2)**0.5 #d)\n",
    "\n",
    "sigma2_es_list = np.geomspace(0.0001,3,num=21) #increasing value in log space\n",
    "sigma2_ker_list = np.geomspace(0.0001,2,num=22) #increasing value in log space\n",
    "\n",
    "mat_out = [] #d)\n",
    "for sigma2_es in sigma2_es_list: #d)\n",
    "    print(sigma2_es) #d)\n",
    "    mat_out_row = [] #d)\n",
    "    for sigma2_ker in sigma2_ker_list: #d)\n",
    "        mat_out_row.append(RMS(x, y, xval, yval, sigma2_es, sigma2_ker)) #d)\n",
    "    mat_out.append(mat_out_row) #d)\n",
    "RMS_mat = np.array(mat_out) #d=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting for d)\n",
    "plt.contour(sigma2_ker_list, sigma2_es_list, np.clip(RMS_mat,-float('inf'),np.percentile(RMS_mat.flat,70)))\n",
    "plt.loglog()\n",
    "plt.colorbar()\n",
    "plt.xlabel(r'$\\sigma^2$')\n",
    "plt.ylabel(r'$\\sigma_e^2$')\n",
    "plt.title(\"NRMS for both hyper parameters\")\n",
    "plt.show()\n",
    "\n",
    "best1, best2 = np.unravel_index(np.argmin(RMS_mat),RMS_mat.shape)\n",
    "sigma2_ker_list[best2], sigma2_es_list[best1]\n",
    "plot(x,y,xtest,sigma2_es_list[best1],sigma2_ker_list[best2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e)** Do the same analysis and grid search for the marginal log-likelihood.\n",
    "\n",
    "$$\n",
    "\\text{loglike} = 1/N \\sum_i \\log \\left ( \\frac{1}{\\sigma \\sqrt{2 \\pi} }  e^{-(y_i-\\hat{y_i})^2/(2 \\sigma_y^2)}  \\right ) \n",
    "$$\n",
    "\n",
    "*tip: rewrite the expression above such to reduce floating-point errors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglike(x, y, xval, yval, sigma2_es, sigma2_ker):\n",
    "    alpha, Kxx = compute_alpha(x, y, sigma2_es, sigma2_ker)\n",
    "    yval_mean_pred, yval_std = pred_mean_and_var(xval, x, Kxx, alpha, sigma2_es, sigma2_ker, return_std=True)\n",
    "    loglike = np.mean(-(yval-yval_mean_pred)**2/(2*yval_std**2) - np.log(yval_std) - np.log(2*np.pi)/2) #e=)\n",
    "    return loglike\n",
    "\n",
    "sigma2_es_list = np.geomspace(0.001,2,num=21)\n",
    "sigma2_ker_list = np.geomspace(0.001,2,num=23)\n",
    "mat_out_like = []\n",
    "for sigma2_es in sigma2_es_list:\n",
    "    print(sigma2_es)\n",
    "    mat_out_row = []\n",
    "    for sigma2_ker in sigma2_ker_list:\n",
    "        mat_out_row.append(loglike(x, y, xval, yval, sigma2_es, sigma2_ker))\n",
    "    mat_out_like.append(mat_out_row)\n",
    "mat_out_like = np.array(mat_out_like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting for e)\n",
    "plt.contour(sigma2_ker_list, sigma2_es_list, np.clip(mat_out_like,np.percentile(mat_out_like.flat,30),float('inf')))\n",
    "plt.colorbar()\n",
    "plt.xlabel(r'$\\sigma^2$')\n",
    "plt.ylabel(r'$\\sigma_e^2$')\n",
    "plt.title(\"NRMS for both hyper parameters\")\n",
    "\n",
    "plt.loglog()\n",
    "plt.show()\n",
    "best1, best2 = np.unravel_index(np.argmax(mat_out_like),mat_out_like.shape)\n",
    "print(sigma2_ker_list[best2], sigma2_es_list[best1])\n",
    "print(np.max(mat_out_like))\n",
    "plot(x,y,xtest,sigma2_es_list[best1],sigma2_ker_list[best2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f)** Does this result of marginal log-likelihood seems sensiable. \n",
    "\n",
    "\n",
    "**Answer f):** Yes, the data is compactly encapsulated by the standard deviation with a $\\sigma_e$ which is not too low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**g)** use `minimize` from `scipy.optimize` to find the maximum log likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "#fun(x, *args) -> float (see docs)\n",
    "\n",
    "# maximize marginal log likelihood\n",
    "fun = lambda th: -loglike(x, y, xval, yval, th[0], th[1]) #f)\n",
    "x0 = [sigma2_es_list[best1],sigma2_ker_list[best2]] #f)\n",
    "fsol = minimize(fun, x0,bounds=[[1e-3,4],[1e-3,4]]) #f=)\n",
    "# fsol = minimize(...)\n",
    "\n",
    "sigma2_es_best, sigma2_ker_best = fsol.x\n",
    "plot(x,y,xtest,sigma2_es_best, sigma2_ker_best)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Using sklearn GP\n",
    "\n",
    "Now that you understand the basics of Gaussian processes let's switch to a nicely implemented version included in sklearn [1.7 Gaussian Processes](https://scikit-learn.org/stable/modules/gaussian_process.html). It includes features like:\n",
    "\n",
    "* The hyperparameters of the kernel are optimized during the fitting of `GaussianProcessRegressor` by maximizing the log-marginal-likelihood (LML) (and using `scipy.optimize.minimize`). \n",
    "* Different kernels can be specified. Common kernels are provided, but it is also possible to specify custom kernels.\n",
    "\n",
    "**a)** Noise term $\\sigma_e$ can be interpreted as a kernel and is used as such in sklearn. Which kind of kernel $k(x_i, x_j)$ would produce the desired behaviour of a noise term?\n",
    "\n",
    "**Answer a):** $k(x_i, x_j) = \\delta_{ij} \\sigma_e$ ($\\delta_{ij}=1$ if $i=j$ and $\\delta_{ij}=0$ if $i\\neq j$.)\n",
    "\n",
    "**b)** Construct a kernel as a combination of a Radial Basis Function `RBF` and a `WhiteKenel` using `+` and estimate a model using the x and y data generated below. Show the resulting model with `.predict` (set `return_std=True`).\n",
    "\n",
    "*tip: read the documentation of Gaussian processes provided here [function doc](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.html), [User guide](https://scikit-learn.org/stable/modules/gaussian_process.html#gaussian-process)*\n",
    "\n",
    "*tip: set n_restarts_optimizer=10 for more robust hyperparamter optimization*\n",
    "\n",
    "*note: sklearn uses multi-variate inputs so the x arrays need to have the shape of `(Nsamp, Nfeatures)` with `Nfeatures=1`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f0 = lambda x: np.sin(3*x) + 0.5*np.random.normal(loc=0,scale=0.9,size=x.shape)\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "np.random.seed(43)\n",
    "N = 100\n",
    "noise = 0.1\n",
    "f0 = lambda x: np.sin(3*x)\n",
    "\n",
    "x = np.random.normal(loc=0,scale=0.8,size=N)\n",
    "y = f0(x) + noise*np.random.normal(loc=0,scale=0.9,size=x.shape)\n",
    "xtest = np.linspace(-4,4,num=150)\n",
    "ytest = f0(xtest)\n",
    "\n",
    "plt.plot(x,y,'.')\n",
    "plt.grid(); plt.xlabel('x'); plt.xlabel('y'); plt.title('Data')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, ExpSineSquared\n",
    "\n",
    "\n",
    "#construct kernel\n",
    "ker = RBF(length_scale=1) + WhiteKernel(noise_level=1.0) #b=)\n",
    "#construct regressor\n",
    "reg = GaussianProcessRegressor(ker,n_restarts_optimizer=10) #b=)\n",
    "#fit regressor\n",
    "reg.fit(x[:,None],y) \n",
    "#use regressor\n",
    "ytest_p, ytest_std = reg.predict(xtest[:,None],return_std=True) #b=)\n",
    "\n",
    "#plot result\n",
    "plt.plot(xtest,ytest,'k',label='$f$')\n",
    "plt.plot(xtest,ytest_p,label='pred mean')\n",
    "plt.xlim(min(xtest),max(xtest))\n",
    "plt.fill_between(xtest,ytest_p-2*ytest_std,ytest_p+2*ytest_std,alpha=0.3,label='pred 2*std')\n",
    "plt.plot(x,y,'.',label='samples')\n",
    "plt.grid(); plt.legend(); plt.xlabel('x'); plt.ylabel('y'); plt.title('sklearn est')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Gaussian processes are probabilistic in nature, hence we can sample them. \n",
    "\n",
    "**c)** Sample the obtained Gaussian process using `reg.sample_y` 7 times on the test set and plot and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ysamps = reg.sample_y(xtest[:,None],n_samples=7) #c=)\n",
    "\n",
    "plt.plot(xtest,ysamps,alpha=0.7)\n",
    "plt.fill_between(xtest,ytest_p-2*ytest_std,ytest_p+2*ytest_std,alpha=0.3)\n",
    "plt.xlim(min(xtest),max(xtest))\n",
    "plt.grid(); plt.xlabel('x'); plt.ylabel('y'); plt.title('GP samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Repeat the exercise trying out some other kernels provided in sklearn [Kernels](https://scikit-learn.org/stable/modules/gaussian_process.html#kernel-operators), for instance, the Exp-Sine-Squared kernel (`ExpSineSquared`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the implementation solving a GP requires solving a system of equations of $A x = y$ with a $A$ a shape of `(Nsamp,Nsamp)` which scales badly with an increasing data size. \n",
    "\n",
    "**e)** Measure the time it takes to estimate a model for different dataset sizes for `range(100,2500,200)` and save the time it takes to an array. Observe the scaling by plotting these saved times. (this computation should not take more than a minute)\n",
    "\n",
    "*tip: use time.time() to get the current time in seconds from the time module*\n",
    "\n",
    "**f)** How does the computation time scale with the number of samples (linear or worse?)\n",
    "\n",
    "**Answer f):** The computational cost grows with $\\mathcal{O}(n^3)$, this is especially visible for high dataset sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, ExpSineSquared\n",
    "import numpy as np\n",
    "def test(Nsamples):\n",
    "    N = Nsamples\n",
    "    noise = 0.1\n",
    "    f0 = lambda x: np.sin(3*x)\n",
    "\n",
    "    x = np.random.normal(loc=0,scale=0.8,size=N)\n",
    "    y = f0(x) + noise*np.random.normal(loc=0,scale=0.9,size=x.shape)\n",
    "\n",
    "    reg = GaussianProcessRegressor(RBF(length_scale=1) + WhiteKernel(noise_level=1.0)) \n",
    "    reg.fit(x[:,None],y) \n",
    "    return reg\n",
    "\n",
    "import time\n",
    "Nsamples_list = range(100,2500,200)\n",
    "time_list = [] #e)\n",
    "for Nsamples in Nsamples_list: #e)\n",
    "    t_start = time.time() #e)\n",
    "    test(Nsamples) #e)\n",
    "    time_elapsed = time.time() - t_start #e)\n",
    "    print(Nsamples, time_elapsed,'seconds') #e)\n",
    "    time_list.append(time_elapsed) #e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting here\n",
    "plt.plot(Nsamples_list,time_list) #e)\n",
    "p = np.polyfit(Nsamples_list,time_list,3) #poly fit #e)\n",
    "f = lambda x: p[0]*x**3 + p[1]*x**2 + p[2]*x + p[3] #e)\n",
    "plt.plot(Nsamples_list,[f(n) for n in Nsamples_list]) #e)\n",
    "comps = \" + \".join([f\"{pi*2000**(3-i):.2} N'^{3-i}\" for i,pi in enumerate(p)]) #e)\n",
    "plt.legend(['time',f'fit {comps}']) #e)\n",
    "print(\"where N'=N/2000\") #e)\n",
    "plt.grid(); plt.xlabel('N'); plt.ylabel('y') #e)\n",
    "plt.show() #e)\n",
    "#here the x**3 term is dominant at N=2000  #e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: NARX GP\n",
    "\n",
    "From the last exercise, we saw that GP can estimate non-linear models. For this exercise we will apply GP to the same example we have used in the last exercise set (Week 1). \n",
    "\n",
    "**a)** Construct the data arrays `Xtrain, Xval, Ytrain, Yval` using the cell below and estimate a GP with RBF and white kernel. Make a residual plot of both the training and validation data. Now also include the uncertainty in the residual plot as a bar plot ([matplotlib errorbar plot](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.errorbar.html))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "def f(upast,ypast):\n",
    "    ukm2, ukm1 = upast\n",
    "    ykm2, ykm1 = ypast\n",
    "    ystar = (0.8 - 0.5 * np.exp(-ykm1 ** 2)) * ykm1 - (0.3 + 0.9 * np.exp(-ykm1 ** 2)) * ykm2 \\\n",
    "           + ukm1 + 0.2 * ukm2 + 0.1 * ukm1 * ukm2\n",
    "    return ystar + np.random.normal(scale=0.01)\n",
    "\n",
    "def get_NARX_data(ulist, f, na, nb):\n",
    "    #init upast and ypast as lists.\n",
    "    upast = [0]*nb \n",
    "    ypast = [0]*na \n",
    "    \n",
    "    ylist = []\n",
    "    for unow in ulist:\n",
    "        #compute the current y given by f\n",
    "        ynow = f(upast,ypast) \n",
    "        \n",
    "        #update past arrays\n",
    "        upast.append(unow)\n",
    "        upast.pop(0)\n",
    "        ypast.append(ynow)\n",
    "        ypast.pop(0)\n",
    "        \n",
    "        #save result\n",
    "        ylist.append(ynow)\n",
    "    return np.array(ylist) #return result\n",
    "\n",
    "na, nb = 2, 2\n",
    "\n",
    "np.random.seed(42)\n",
    "N = 500\n",
    "ulist = np.random.normal(scale=1,size=N)\n",
    "ylist = get_NARX_data(ulist,f,na,nb)\n",
    "\n",
    "def make_training_data(ulist,ylist,na,nb):\n",
    "    #Xdata = (Nsamples,Nfeatures)\n",
    "    #Ydata = (Nsamples)\n",
    "    Xdata = []\n",
    "    Ydata = []\n",
    "    #for loop over the data:\n",
    "    for k in range(max(na,nb),len(ulist)): #skip the first few indexes such to \n",
    "        Xdata.append(np.concatenate([ulist[k-nb:k],ylist[k-na:k]])) \n",
    "        Ydata.append(ylist[k]) \n",
    "    return np.array(Xdata), np.array(Ydata)\n",
    "\n",
    "Xdata, Ydata = make_training_data(ulist,ylist, na, nb)\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "Xtrain, Xval, Ytrain, Yval = train_test_split(Xdata, Ydata) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, ExpSineSquared\n",
    "\n",
    "ker = RBF(length_scale=0.1) + WhiteKernel(noise_level=0.01) #e=)\n",
    "reg = GaussianProcessRegressor(ker, n_restarts_optimizer=10) #e=)\n",
    "reg.fit(Xtrain,Ytrain) #e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#residual calculations and plotting\n",
    "Ytrain_pred, Ytrain_pred_std = reg.predict(Xtrain,return_std=True) #e)\n",
    "plt.figure(figsize=(12,5)) #e)\n",
    "plt.plot(Ytrain) #e)\n",
    "Ytrain_pred, Ytrain_pred_std = reg.predict(Xtrain,return_std=True) #e)\n",
    "plt.errorbar(np.arange(len(Xtrain)), (Ytrain_pred), yerr=2*Ytrain_pred_std,fmt='.r') #e)\n",
    "plt.grid(); plt.xlabel('sample'); plt.ylabel('y'); plt.legend(['measured','pred'])#e)\n",
    "plt.show() #e)\n",
    "\n",
    "plt.figure(figsize=(12,5)) #e)\n",
    "plt.plot(Yval) #e)\n",
    "Yval_pred, Yval_pred_std = reg.predict(Xval,return_std=True) #e)\n",
    "plt.errorbar(np.arange(len(Xval)), (Yval_pred), yerr=2*Yval_pred_std,fmt='.r') #e)\n",
    "plt.grid(); plt.xlabel('sample'); plt.ylabel('y'); plt.legend(['measured','pred'])#e)\n",
    "plt.show() #e)\n",
    "\n",
    "print(f'Validation NRMS= {np.mean((Yval_pred-Yval)**2)**0.5/np.std(Yval)}')#e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** We are also interested in the simulation performance of the model. Make a simulation and plot the residual and the NRMS. Is it lower than the polynomial model of the last exercise set?\n",
    "\n",
    "**c)** Retry the exercise with different kernels and see if you can construct a kernel that is more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(43)\n",
    "utest = np.random.normal(scale=1.0,size=5000)\n",
    "ytest = get_NARX_data(utest,f,na,nb)\n",
    "\n",
    "\n",
    "model_now = reg #b=)\n",
    "ytest_sim = get_NARX_data(utest,lambda u,y: model_now.predict(np.concatenate([u,y])[None,:])[0], na, nb)\n",
    "plt.plot(ytest) #b)\n",
    "plt.plot(ytest-ytest_sim) #b)\n",
    "plt.grid(); plt.xlabel('index time'); plt.ylabel('y'); plt.legend(['measured','pred']) #b)\n",
    "plt.show() #b)\n",
    "\n",
    "print('NRMS=',np.mean((ytest-ytest_sim)**2)**0.5/np.std(ytest)) #b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Bayesian optimization\n",
    "\n",
    "\n",
    "In this exercise, we will explore the basics of Bayesian optimization. Consider the same setting as in Exercise 2, but now with a slightly modified process as seen below. \n",
    "\n",
    "**a)** For a given set of 1-dimensional inputs and outputs estimate a GP regressor in `get_model` with an `RBF` kernel and a `WhiteKernel`. Also, write `get_mean_std` which returns the mean and the standard deviation for a given regressor and test points.\n",
    "\n",
    "**b)** Write the acquisition variance (`acquisition_var`) which takes in a number of test points and returns the estimated quality of picking this point based on the variance. \n",
    "\n",
    "**c)** Write the main `bayesian_optimization` function which in the first part samples `f` uniformly on the interval of `xmin` to `xmax` for `n_initial` points. Afterwards it should use the maximum of `acquisition_fun` (using `xtest_points`) to sample `f` more efficently until having `n_max` points. Define the test set as `xtest = np.linspace(-3,3,num=1000)`. Visualize the results using the plotting already present below. \n",
    "\n",
    "*tip: use np.argmax and np.append*\n",
    "\n",
    "**d)** Also implement an acquisition function that weights the mean and the variance given by $\\mu(x) (1-w) + \\sigma(x) w$ which aims to find the maximum of the function while incorporating the variance of the function. Implement the `acquisition_weighted_mean_and_var` function and switching `have_d_been_implemented` to True. How does the behavior change for different values of $w$?\n",
    "\n",
    "There are many options for acquisition function, Further reading: https://distill.pub/2020/bayesian-optimization/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, ExpSineSquared, ConstantKernel\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\") #there might be some warning but this will supress them.\n",
    "\n",
    "if True: #feel free to change the function to observe different different behaviour.\n",
    "    f0 = lambda x: np.sin(3*x) + 0.2*x + 0.3 #no noise version\n",
    "    xmin, xmax = -3., 3.\n",
    "else:\n",
    "    f0 = lambda x: x/20+x**2-x**4+np.exp(-(20*x)**2)/4\n",
    "    xmin, xmax = -1., 1.\n",
    "f = lambda x: f0(x) + np.random.normal(scale=0.002,size=np.array(x).shape) #noisy version\n",
    "\n",
    "def get_model(x,y): \n",
    "    #return a regressor which is fitted to x,y\n",
    "    ker = RBF(length_scale=0.4,length_scale_bounds=(0.01,5.0)) + \\\n",
    "          WhiteKernel(noise_level=1e-6,noise_level_bounds=(1e-7,1e-2)) #a)\n",
    "    gp_reg = GaussianProcessRegressor(ker, n_restarts_optimizer=10) #a)\n",
    "    gp_reg.fit(x[:,None],y) #a)\n",
    "    return gp_reg #a)\n",
    "\n",
    "def get_mean_std(gp_reg, xtest_points):\n",
    "    ytest_pred_mean, ytest_pred_std = gp_reg.predict(xtest_points[:,None],return_std=True) #a)\n",
    "    return ytest_pred_mean, ytest_pred_std\n",
    "    \n",
    "def acquisition_var(gp_reg, xtest_points):\n",
    "    ytest_pred_mean, ytest_pred_std = get_mean_std(gp_reg, xtest_points) #b)\n",
    "    return ytest_pred_std #b)\n",
    "\n",
    "def acquisition_weighted_mean_and_var(gp_reg, xtest_points, weight=0.5):\n",
    "    pass\n",
    "    ytest_pred_mean, ytest_pred_std = get_mean_std(gp_reg, xtest_points) #d)\n",
    "    return (1-weight)*ytest_pred_mean + weight*ytest_pred_std #d)\n",
    "\n",
    "def bayesian_optimization(f, xmin, xmax, acquisition_fun, n_initial=5, n_max=15, seed=22):\n",
    "    # f : is the function which need to be sampled\n",
    "    # xmin : and xmax are the bounds on the x\n",
    "    # acquisition_fun(gp_reg, some_x_points) : is the acquisition_fun on which the maximum need to be chosen as next point\n",
    "    # n_initial : the number of points which are uniformly sampled from f before using bayesian optimizaiton\n",
    "    # n_max : the buget of the number of maximum points that can be sampled from f \n",
    "    # (i.e. n_initial - n_max is the number of bayesian samples)\n",
    "    \n",
    "    rng = np.random.RandomState(seed) #you can use rng as a random generator, (e.g. rng.uniform(xmin, xmax) will sample uniform)\n",
    "    x = rng.uniform(xmin, xmax, size=n_initial) #c=)\n",
    "    y = f(x) #c=)\n",
    "    xtest_points = np.linspace(xmin, xmax, num=1000) #c=)\n",
    "    for n in range(n_initial+1, n_max+1): #c)\n",
    "        gp_reg = get_model(x,y)\n",
    "        acquisition_vals = acquisition_fun(gp_reg, xtest_points) #c=)\n",
    "        xnew = xtest_points[np.argmax(acquisition_vals)] #c=)\n",
    "        ynew = f(xnew) #c=)\n",
    "        x = np.append(x,xnew) #c=)\n",
    "        y = np.append(y,ynew) #c=)\n",
    "    return x, y, get_model(x,y)\n",
    "\n",
    "n_initial = 5\n",
    "n_max = 15\n",
    "\n",
    "rng = np.random.RandomState(21)\n",
    "x_rand = rng.uniform(xmin, xmax, size=n_max) #random baseline\n",
    "y_rand = f(x_rand)\n",
    "x_test = np.linspace(xmin-0.05,xmax+0.05,num=500)\n",
    "\n",
    "have_d_been_implemented = False  #switch to true when working on **d)**\n",
    "if have_d_been_implemented:\n",
    "    weight = 0.8\n",
    "    #incorporate the weight factor in the function with a lambda function\n",
    "    acquisition_weighted_mean_and_var_now = lambda gp_reg, xtest_points: \\\n",
    "        acquisition_weighted_mean_and_var(gp_reg, xtest_points, weight=weight)\n",
    "else:\n",
    "    acquisition_weighted_mean_and_var_now = None\n",
    "    \n",
    "for mode,acquisition_fun in enumerate([acquisition_var,acquisition_weighted_mean_and_var_now]):\n",
    "    if acquisition_fun==None:\n",
    "        continue\n",
    "    if mode==0:\n",
    "        print('Variance Acquision')\n",
    "    else:\n",
    "        print(f'Weighted mean and Variance Acquision (weight={weight})')\n",
    "    #Bayesian\n",
    "    x, y, reg = bayesian_optimization(f, xmin, xmax, acquisition_fun=acquisition_fun, n_initial=n_initial, n_max=n_max, seed=21)\n",
    "\n",
    "    plt.figure(figsize=(12,4))\n",
    "    for i,(xi, yi) in enumerate([(x_rand,y_rand),(x,y)]):\n",
    "        plt.subplot(1,2,i+1)\n",
    "        plt.plot(x_test,f(x_test),label='real')\n",
    "\n",
    "        label = 'random samples' if i==0 else 'bayesian optimization'\n",
    "        plt.plot(xi,yi,'o',label=label)\n",
    "\n",
    "        reg = get_model(xi,yi)\n",
    "\n",
    "        ytest_pred_mean, ytest_pred_std = get_mean_std(reg, x_test)\n",
    "        plt.plot(x_test, ytest_pred_mean,label='pred mean')\n",
    "        plt.fill_between(x_test, \\\n",
    "                         ytest_pred_mean+1.92*ytest_pred_std,\\\n",
    "                         ytest_pred_mean-1.92*ytest_pred_std,\\\n",
    "                         alpha=0.2,label='92% var')\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.ylabel('y')\n",
    "        plt.xlabel('x')\n",
    "    plt.show()\n",
    "    \n",
    "    if mode==1:\n",
    "        M = x_test[np.argmax(f0(x_test))]\n",
    "        x_near = np.linspace(M-0.05, M+0.05,num=300)\n",
    "        plt.plot(x_near, f0(x_near),label='real')\n",
    "        xlim, ylim = plt.xlim(), plt.ylim()\n",
    "        plt.plot(xi,yi,'o',label='bayese samples')\n",
    "        plt.xlim(xlim); plt.ylim(ylim)\n",
    "        plt.plot(x_near, reg.predict(x_near[:,None]),label='pred')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.ylabel('y')\n",
    "        plt.xlabel('x')\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid-based optimization that we used above is not guaranteed to find the global\n",
    "optimum of the selection problem precisely, neither is it applicable in case of high-dimensional regression spaces.\n",
    "Hence, direct maximization over the covariance function is suggested.\n",
    "However, in that case the problem of finding the global optimum can still seriously affect the\n",
    "outcome. Hence, random initializations or swarm optimization can achieve better outcomes.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "19280aba9224dc1b53dd204eff4ce08f2ac63fb040baaa9a4d901d7c4c50f8b5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('PyTorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
